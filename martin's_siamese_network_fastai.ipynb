{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is my attempt to use martin's data creation technique and then put it in Siamene Network using Fast AI. I am using following links for this:\n",
    "https://www.kaggle.com/martinpiotte/whale-recognition-model-with-score-0-78563/output\n",
    "https://github.com/radekosmulski/whale/blob/master/siamese_network_prototype.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress annoying stderr output when importing keras.\n",
    "import sys\n",
    "import platform\n",
    "old_stderr = sys.stderr\n",
    "sys.stderr = open('/dev/null' if platform.system() != 'Windows' else 'nul', 'w')\n",
    "\n",
    "sys.stderr = old_stderr\n",
    "\n",
    "import random\n",
    "from scipy.ndimage import affine_transform\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "# Determise the size of each image\n",
    "from os.path import isfile\n",
    "from PIL import Image as pil_image\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from pandas import read_csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/whale/train.csv')\n",
    "im_count = df[df.Id != 'new_whale'].Id.value_counts()\n",
    "im_count.name = 'sighting_count'\n",
    "df = df.join(im_count, on='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training data, we are taking all the images except for the category - New Whale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data for training  (15697, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/FRACTAL/jitesh.arora/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id\n",
       "0  0000e88ab.jpg  w_f48451c\n",
       "1  0001f9222.jpg  w_c3d896a"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df[df['Id']!= 'new_whale']\n",
    "#new_df = new_df[new_df['sighting_count']>1]\n",
    "\n",
    "print('shape of data for training ',new_df.shape)\n",
    "new_df.drop(columns = ['sighting_count'] , inplace=True)\n",
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15694</th>\n",
       "      <td>fff7faf61.jpg</td>\n",
       "      <td>w_9cf0388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15695</th>\n",
       "      <td>fff9002e0.jpg</td>\n",
       "      <td>w_bd1c3d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15696</th>\n",
       "      <td>fffcde6fe.jpg</td>\n",
       "      <td>w_9f30885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Image         Id\n",
       "15694  fff7faf61.jpg  w_9cf0388\n",
       "15695  fff9002e0.jpg  w_bd1c3d5\n",
       "15696  fffcde6fe.jpg  w_9f30885"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.reset_index(inplace=True)\n",
    "new_df.drop(columns='index' , inplace=True)\n",
    "new_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The data set we are using for training contains all images except of new whales.\n",
    "we don't require creating phase values for this  datasets , as duplicate images are very few.\n",
    "i am using index present in train.csv as the phase value as we can use it for indexing very easily \n",
    "\"\"\"\n",
    "\n",
    "tagged = dict([(p,w) for _,p,w in new_df.to_records()])\n",
    "h2ps = dict([(idx , p ) for   idx,p,w in new_df.to_records()])\n",
    "p2h   = dict([(p , idx) for idx , p , w in new_df.to_records()])\n",
    "h2p = h2ps.copy()\n",
    "join = tagged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba62ac1b29164d36964e97c6c28a6284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15697), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15697,\n",
       " [('0000e88ab.jpg', (224, 224)),\n",
       "  ('0001f9222.jpg', (224, 224)),\n",
       "  ('00029d126.jpg', (224, 224)),\n",
       "  ('000a6daec.jpg', (224, 224)),\n",
       "  ('0016b897a.jpg', (224, 224))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_path(p):\n",
    "    if isfile('data/whale/train-224/' + p): return 'data/whale/train-224/' + p\n",
    "    if isfile('data/whale/test-224/' + p): return 'data/whale/test-224/' + p\n",
    "    return p\n",
    "\n",
    "p2size = {}\n",
    "for p in tqdm_notebook(join):\n",
    "    size      = pil_image.open(expand_path(p)).size\n",
    "    p2size[p] = size\n",
    "len(p2size), list(p2size.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15697"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## phase value for all categories except new whale\n",
    "h2ws = {}\n",
    "new_whale = 'new_whale'\n",
    "for p,w in tagged.items():\n",
    "    if w != new_whale: # Use only identified whales\n",
    "        h = p2h[p]\n",
    "        if h not in h2ws: h2ws[h] = []\n",
    "        if w not in h2ws[h]: h2ws[h].append(w)\n",
    "for h,ws in h2ws.items():\n",
    "    if len(ws) > 1:\n",
    "        h2ws[h] = sorted(ws)\n",
    "len(h2ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5004"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for each whale category, observe the associated phase values , \n",
    "##store all whale categories even the categories with just one image ( this is  different from martin's approach)\n",
    "\n",
    "w2hs = {}\n",
    "for h,ws in h2ws.items():\n",
    "    if len(ws) == 1: # Use only unambiguous pictures\n",
    "\n",
    "        w = ws[0]\n",
    "        if w not in w2hs: w2hs[w] = []\n",
    "        if h not in w2hs[w]: w2hs[w].append(h)\n",
    "for w,hs in w2hs.items():\n",
    "    #if len(hs) > 1:\n",
    "        w2hs[w] = sorted(hs)\n",
    "len(w2hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15697"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h2ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_image(p):\n",
    "    img = pil_image.open(expand_path(p))\n",
    "    return img\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [] # A list of  indices of images to be used in training data.\n",
    "for hs in w2hs.values():\n",
    "    if len(hs) >= 1:\n",
    "        train += hs\n",
    "random.shuffle(train)\n",
    "train_set = set(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15697, 5004)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we have whales categories with phases(images) more than 1. shuffle the phase values now.\n",
    "w2ts = {} #Associate the image index from train to each whale id.\n",
    "for w,hs in w2hs.items():\n",
    "    for h in hs:\n",
    "        if h in train_set:\n",
    "            if w not in w2ts: w2ts[w] = []\n",
    "            if h not in w2ts[w]: w2ts[w].append(h)\n",
    "for w,ts in w2ts.items(): w2ts[w] = np.array(ts)\n",
    "## then again for each whale categories see how many images you have , \n",
    "## you are working with 5004 whale categories and 15697 images \n",
    "    \n",
    "    \n",
    "t2i = {} # The position in train of each training image id\n",
    "for i,t in enumerate(train): t2i[t] = i\n",
    "\n",
    "len(train),len(w2ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import Sequence\n",
    "# import keras\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "import random\n",
    "#from keras import backend as K\n",
    "\n",
    "try:\n",
    "    from lap import lapjv\n",
    "    segment = False\n",
    "except ImportError:\n",
    "    print('Module lap not found, emulating with much slower scipy.optimize.linear_sum_assignment')\n",
    "    segment = True\n",
    "    from scipy.optimize import linear_sum_assignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import functions from fast ai library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy_thresh\n",
    "from fastai.basic_data import *\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "from fastai.callbacks.hooks import num_features_model, model_sizes\n",
    "from fastai.layers import BCEWithLogitsFlat\n",
    "from fastai.basic_train import Learner\n",
    "from skimage.util import montage\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import re\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "from functional import seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'resnet18_martin_data'\n",
    "\n",
    "fn2label = {row[1].Image: row[1].Id for row in df.iterrows()}  #new_\n",
    "path2fn = lambda path: re.search('\\w*\\.jpg$', path).group(0)\n",
    "\n",
    "\n",
    "SZ = 224\n",
    "BS = 64//4\n",
    "NUM_WORKERS = 12\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset for all the training images. Because of some reason , i am not able to create validation set as well ( produces error while indexing from match and unmatch matrices. If someone is able to find the work arounf the help will be appreciated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df.Id.unique()\n",
    "data = (\n",
    "    ImageItemList  ##df[(df.Id != 'new_whale') & (df.sighting_count >1)]\n",
    "        .from_df( df[(df.Id != 'new_whale')], f'data/whale/train-{SZ}', cols=['Image'])\n",
    "        .no_split()##split_by_valid_func(lambda path: path2fn(path) in val_fns) \n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)] ,  classes=classes)\n",
    "        .add_test(ImageItemList.from_folder(f'data/whale/test-{SZ}'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15697\n",
      "15697\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(data.train.x))\n",
    "print(len(data.valid.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "import random\n",
    "\n",
    "# First try to use lapjv Linear Assignment Problem solver as it is much faster.\n",
    "# At the time I am writing this, kaggle kernel with custom package fail to commit.\n",
    "# scipy can be used as a fallback, but it is too slow to run this kernel under the time limit\n",
    "# As a workaround, use scipy with data partitioning.\n",
    "# Because algorithm is O(n^3), small partitions are much faster, but not what produced the submitted solution\n",
    "try:\n",
    "    from lap import lapjv\n",
    "    segment = False\n",
    "except ImportError:\n",
    "    print('Module lap not found, emulating with much slower scipy.optimize.linear_sum_assignment')\n",
    "    segment = True\n",
    "    from scipy.optimize import linear_sum_assignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TwoImDataset creation is the part where I am trying to replicate 'TrainingData Class' from https://www.kaggle.com/martinpiotte/whale-recognition-model-with-score-0-78563/output\n",
    "For whale categories having just one images in training data , matching pair -  same image pair (A,A) . For other categories it creates a de arrangement.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_even(num): return num % 2 == 0\n",
    "\n",
    "class TwoImDataset(Dataset):\n",
    "    def __init__(self, ds ,score  , steps = 1000):\n",
    "        self.ds = ds\n",
    "        self.whale_ids = ds.y.items\n",
    "        self.steps =1000\n",
    "        self.score  = -score\n",
    "        for ts in w2ts.values():\n",
    "            idxs =  ts.copy() #[t2i[t] for t in ts]\n",
    "            #idxs = [i for i in  idxs if i <score.shape[0]]\n",
    "            for i in idxs:\n",
    "                for j in idxs:\n",
    "                    self.score[i,j] = 10000.0   # Set a large value for matching\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 2 * len(self.ds)\n",
    "    def __getitem__(self, idx):\n",
    "        if is_even(idx):\n",
    "            return self.sample_image(idx // 2 , 1)\n",
    "        else: return self.sample_image((idx-1) // 2 ,0)        \n",
    "\n",
    "    def sample_image(self, idx , tag):\n",
    "        #set_trace()\n",
    "        if tag==0:\n",
    "            first_image_id =  self.match[idx][0]\n",
    "            second_image_id = self.match[idx][1]\n",
    "            #if first_image_id < len(self.ds) and second_image_id< len(self.ds):         \n",
    "            return self.construct_example(self.ds[first_image_id][0], self.ds[second_image_id][0], 1)\n",
    "        else:\n",
    "            first_image_id =  self.unmatch[idx][0]\n",
    "            second_image_id = self.unmatch[idx][1]     \n",
    "            return self.construct_example(self.ds[first_image_id][0], self.ds[second_image_id][0], 0)\n",
    "  \n",
    "    def on_epoch_end(self):\n",
    "        if self.steps <= 0: return # Skip this on the last epoch.\n",
    "        self.steps     -= 1\n",
    "        self.match      = []\n",
    "        self.unmatch    = []\n",
    "        if segment:\n",
    "            tmp   = []\n",
    "            batch = 512\n",
    "            for start in range(0, score.shape[0], batch):\n",
    "                end = min(score.shape[0], start + batch)\n",
    "                _, x = linear_sum_assignment(self.score[start:end, start:end])\n",
    "                tmp.append(x + start)\n",
    "            x = np.concatenate(tmp)\n",
    "        else:\n",
    "            _,_,x = lapjv(self.score) # Solve the linear assignment problem\n",
    "        y = np.arange(len(x),dtype=np.int32)\n",
    "\n",
    "        # Compute a derangement for matching whales\n",
    "        for ts in w2ts.values():\n",
    "            d = ts.copy()\n",
    "            if (len(d)==1):\n",
    "                for ab in zip(ts,d): self.match.append(ab)\n",
    "            else:                \n",
    "                while True:\n",
    "                    random.shuffle(d)\n",
    "                    if not np.any(ts == d): break\n",
    "                for ab in zip(ts,d): self.match.append(ab)\n",
    "\n",
    "        # Construct unmatched whale pairs from the LAP solution.\n",
    "        for i,j in zip(x,y):\n",
    "            if i == j:\n",
    "                print(self.score)\n",
    "                print(x)\n",
    "                print(y)\n",
    "                print(i,j)\n",
    "            assert i != j\n",
    "            self.unmatch.append((train[i],train[j]))\n",
    "\n",
    "        # Force a different choice for an eventual next epoch.\n",
    "        self.score[x,y] = 10000.0\n",
    "        self.score[y,x] = 10000.0\n",
    "        random.shuffle(self.match)\n",
    "        random.shuffle(self.unmatch)\n",
    "        print('end of epoch',self.match[0][0])\n",
    "        print('end of epoch',self.unmatch[0][0])\n",
    "        \n",
    "        print(len(self.match), len(train), len(self.unmatch), len(train))\n",
    "        #assert len(self.match) == len(train) and len(self.unmatch) == len(train)\n",
    "    \n",
    "    def construct_example(self, im_A, im_B, class_idx):\n",
    "        return [im_A, im_B], class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of epoch 13301\n",
      "end of epoch 2316\n",
      "15697 15697 15697 15697\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create a 2D score matrix of size of training data\n",
    "\"\"\"\n",
    "\n",
    "score = np.random.random_sample(size=(len(train),len(train)))\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    TwoImDataset(data.train , score),\n",
    "    batch_size=BS,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_batch(batch):\n",
    "    stat_tensors = [torch.tensor(l).cuda() for l in imagenet_stats]\n",
    "    return [normalize(batch[0][0], *stat_tensors), normalize(batch[0][1], *stat_tensors)], batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch = ImageDataBunch(train_dl , train_dl) ##, valid_dl\n",
    "data_bunch.add_tfm(normalize_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The netowrk architecture is also inspired from Martin's notebook (part after we extract features for two image pairs)\n",
    "\"\"\"\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, arch=models.resnet18):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.cnn = create_body(arch)\n",
    "        self.head = nn.Linear(num_features_model(self.cnn), 1)  #\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1 , 32 , kernel_size= (1 , 4) , padding = 0 ,stride=1)\n",
    "        self.conv2 = nn.Conv2d( 1 , 1 , kernel_size = (32 ,1 ) , padding = 0  , stride=1)\n",
    "\n",
    "    def forward(self, im_A, im_B):\n",
    "        x1, x2 = seq(im_A, im_B).map(self.cnn).map(self.process_features)\n",
    "        d1 = self.calculate_distance(x1, x2)\n",
    "        d2 = (x1 + x2)\n",
    "        d3 = (x1*x2)\n",
    "        d4 = (x1-x2)*(x1 - x2)\n",
    "        concat_layer = torch.cat([d1 ,d2,d3, d4]  ,dim = 1)\n",
    "        concat_layer = concat_layer.view( - 1, 1, num_features_model(self.cnn) , 4)   ## no of channels is second dimension\n",
    "        concat_layer  = F.relu(self.conv1(concat_layer))\n",
    "        concat_layer = concat_layer.view(-1 ,1,32, num_features_model(self.cnn)  )\n",
    "        concat_layer = F.relu(self.conv2(concat_layer))\n",
    "        concat_layer_fn = concat_layer.view(-1 ,num_features_model(self.cnn) )\n",
    "        out = self.head(concat_layer_fn)\n",
    "        return out\n",
    "    \n",
    "    def process_features(self, x): \n",
    "        y = x.reshape(*x.shape[:2], -1)\n",
    "        return x.reshape(*x.shape[:2], -1).max(-1)[0]\n",
    "    def calculate_distance(self, x1, x2): return (x1 - x2).abs_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data_bunch, SiameseNetwork(), loss_func=BCEWithLogitsFlat(), metrics=[lambda preds, targs: accuracy_thresh(preds.squeeze(), targs, sigmoid=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.split([learn.model.cnn[:6], learn.model.cnn[6:], learn.model.head])\n",
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 11:56 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th><lambda></th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.388826</th>\n",
       "    <th>0.401715</th>\n",
       "    <th>0.791776</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.310544</th>\n",
       "    <th>0.298000</th>\n",
       "    <th>0.862076</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.265223</th>\n",
       "    <th>0.263870</th>\n",
       "    <th>0.864305</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.235134</th>\n",
       "    <th>0.237953</th>\n",
       "    <th>0.892177</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4 , 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 5e-4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 47:34 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th><lambda></th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.199618</th>\n",
       "    <th>0.226004</th>\n",
       "    <th>0.892973</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.221874</th>\n",
       "    <th>0.229621</th>\n",
       "    <th>0.882048</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.232100</th>\n",
       "    <th>0.221465</th>\n",
       "    <th>0.887208</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.205440</th>\n",
       "    <th>0.163407</th>\n",
       "    <th>0.932185</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.171731</th>\n",
       "    <th>0.138759</th>\n",
       "    <th>0.942664</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.141226</th>\n",
       "    <th>0.106391</th>\n",
       "    <th>0.956202</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.095533</th>\n",
       "    <th>0.072366</th>\n",
       "    <th>0.972606</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.062427</th>\n",
       "    <th>0.053985</th>\n",
       "    <th>0.981525</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.053467</th>\n",
       "    <th>0.044704</th>\n",
       "    <th>0.984679</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.038683</th>\n",
       "    <th>0.042204</th>\n",
       "    <th>0.985475</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'{name}-stage2_unfz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'{name}-stage2_unfz');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 1:04:21 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th><lambda></th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.048071</th>\n",
       "    <th>0.046917</th>\n",
       "    <th>0.981780</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.085961</th>\n",
       "    <th>0.116492</th>\n",
       "    <th>0.940753</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.134944</th>\n",
       "    <th>0.104413</th>\n",
       "    <th>0.961872</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.110086</th>\n",
       "    <th>0.108361</th>\n",
       "    <th>0.945117</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.110862</th>\n",
       "    <th>0.073613</th>\n",
       "    <th>0.968019</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.076461</th>\n",
       "    <th>0.046970</th>\n",
       "    <th>0.980729</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.034342</th>\n",
       "    <th>0.032400</th>\n",
       "    <th>0.984965</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.019661</th>\n",
       "    <th>0.018537</th>\n",
       "    <th>0.992960</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.014298</th>\n",
       "    <th>0.012686</th>\n",
       "    <th>0.995604</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.012486</th>\n",
       "    <th>0.013554</th>\n",
       "    <th>0.995764</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'{name}-stage3_unfz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'{name}-stage3_unfz');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_whale_fns = set(df[df['Id']=='new_whale'].sample(frac = 1).Image.iloc[:1000])\n",
    "#new_whale_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'sighting_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-49038326f4b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_fns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msighting_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_fns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_whale_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sighting_count'"
     ]
    }
   ],
   "source": [
    "val_fns = set(df[df.sighting_count == 2].Image)\n",
    "print(len(val_fns) + len(new_whale_fns))\n",
    "\n",
    "classes = df.Id.unique()\n",
    "\n",
    "df = df.drop(columns = ['sighting_count'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df, f'data/whale/train-{SZ}', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns) ##.union(new_whale_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)], classes=classes)\n",
    "        .add_test(ImageItemList.from_folder(f'data/whale/test-{SZ}'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2570, 512])\n",
      "CPU times: user 3.48 s, sys: 1.82 s, total: 5.3 s\n",
      "Wall time: 5.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "targs = []\n",
    "feats = []\n",
    "learn.model.eval()\n",
    "for ims, ts in data.valid_dl:\n",
    "    feats.append(learn.model.process_features(learn.model.cnn(ims)).detach().cpu())  ##\n",
    "    targs.append(ts)\n",
    "\n",
    "feats = torch.cat(feats)\n",
    "print(feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 3.25 s, total: 1min 20s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sims = []\n",
    "for feat in feats:\n",
    "    x1 = feats#.copy()\n",
    "    x2 = feat.unsqueeze(0).repeat(2570 ,1)\n",
    "    d1 = learn.model.calculate_distance(x1 , x2)\n",
    "    d2 = (x1 + x2)\n",
    "    d3 = (x1*x2)\n",
    "    d4 = (x1-x2)*(x1 - x2)\n",
    "    concat_layer = torch.cat([d1 ,d2,d3, d4]  ,dim = 1)\n",
    "    concat_layer = concat_layer.view( - 1, 1, num_features_model(learn.model.cnn) , 4)   ## no of channels is second dimension\n",
    "    concat_layer  = F.relu(learn.model.conv1(concat_layer.cuda()))\n",
    "    concat_layer = concat_layer.view(-1 ,1,32, num_features_model(learn.model.cnn)  )\n",
    "    concat_layer = F.relu(learn.model.conv2(concat_layer))\n",
    "    concat_layer_fn = concat_layer.view(-1 ,num_features_model(learn.model.cnn) )\n",
    "    #out = learn.model.head(concat_layer_fn)\n",
    "    predicted_similarity = learn.model.head(concat_layer_fn).sigmoid_()  #.cuda()\n",
    "    sims.append(predicted_similarity.squeeze().detach().cpu())\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2570"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_whale_idx = np.where(classes == 'new_whale')[0][0]\n",
    "new_whale_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 852 ms, sys: 0 ns, total: 852 ms\n",
      "Wall time: 850 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top_5s = []\n",
    "for i, sim in enumerate(sims):\n",
    "    idxs = sim.argsort(descending=True)\n",
    "    probs = sim[idxs]\n",
    "    top_5 = []\n",
    "    for j, p in zip(idxs, probs):\n",
    "        if len(top_5) == 5: break\n",
    "        if j == i: continue   \n",
    "        predicted_class = data.valid_ds.y.items[j]\n",
    "        \"\"\"\n",
    "        we dont want to predict new whale for validation data \n",
    "        \"\"\"\n",
    "        if predicted_class == new_whale_idx: continue\n",
    "        if predicted_class not in top_5: top_5.append(predicted_class)\n",
    "    top_5s.append(top_5)\n",
    "    \n",
    "## top 5 contains 5 best predicted classes ,w ith indices from classes dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 4753, 2555, 3146, 1911],\n",
       " [3030, 2072, 4294, 2673, 3043],\n",
       " [1982, 3065, 177, 14, 3405],\n",
       " [15, 3157, 1530, 3572, 4087],\n",
       " [2890, 24, 1791, 3167, 2447]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5s[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5175356679636836"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "mapk of validation data set without having new whales in predictions. \n",
    "\"\"\"\n",
    "mapk(data.valid_ds.y.items.reshape(-1,1), np.stack(top_5s), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.49298786181139126\n",
      "0.7272727272727272 0.49298786181139126\n",
      "0.7545454545454545 0.49298786181139126\n",
      "0.7818181818181817 0.49298786181139126\n",
      "0.8090909090909091 0.49298786181139126\n",
      "0.8363636363636363 0.49298786181139126\n",
      "0.8636363636363636 0.49298786181139126\n",
      "0.8909090909090909 0.49298786181139126\n",
      "0.9181818181818182 0.49298786181139126\n",
      "0.9454545454545454 0.49298786181139126\n",
      "0.9727272727272727 0.49298786181139126\n",
      "1.0 0.4986881419234361\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\"\"\"\n",
    "trying to calcualte threshold probability for new whale, which maximises the mapk for validation data.\n",
    "\"\"\"\n",
    "\n",
    "for thresh in np.linspace(0.7, 1, 12):\n",
    "    top_5s = []\n",
    "    for i, sim in enumerate(sims):\n",
    "        idxs = sim.argsort(descending=True)\n",
    "        probs = sim[idxs]\n",
    "        top_5 = []\n",
    "        for j, p in zip(idxs, probs):\n",
    "            if new_whale_idx not in top_5 and p < thresh and len(top_5) < 5: top_5.append(new_whale_idx)\n",
    "            if len(top_5) == 5: break\n",
    "            if j == i: continue\n",
    "            predicted_class = data.valid_ds.y.items[j]\n",
    "            if predicted_class not in top_5: top_5.append(predicted_class)\n",
    "        top_5s.append(top_5)\n",
    "    print(thresh, mapk(data.valid_ds.y.items.reshape(-1,1), np.stack(top_5s), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df, f'data/whale/train-{SZ}', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in {'69823499d.jpg'}) # in newer version of the fastai library there is .no_split that could be used here\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)], classes=classes)\n",
    "        .add_test(ImageItemList.from_folder(f'data/whale/test-{SZ}'))\n",
    "        .transform(None, size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.64 s, sys: 3.56 s, total: 13.2 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_feats = []\n",
    "learn.model.eval()\n",
    "for ims, _ in data.test_dl:\n",
    "    test_feats.append(learn.model.process_features(learn.model.cnn(ims)).detach().cpu())\n",
    "    \n",
    "    \n",
    "test_feats = torch.cat(test_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 s, sys: 8.31 s, total: 39.3 s\n",
      "Wall time: 40.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_feats = []\n",
    "train_class_idxs = []\n",
    "learn.model.eval()\n",
    "for ims, t in data.train_dl:\n",
    "    train_feats.append(learn.model.process_features(learn.model.cnn(ims)).detach().cpu())\n",
    "    train_class_idxs.append(t)\n",
    "    \n",
    "train_class_idxs = torch.cat(train_class_idxs)\n",
    "train_feats = torch.cat(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25360"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_class_idxs)\n",
    "len(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35min 38s, sys: 27min 52s, total: 1h 3min 30s\n",
      "Wall time: 1h 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sims = []\n",
    "for feat in test_feats:\n",
    "    dists = learn.model.calculate_distance(train_feats, feat.unsqueeze(0).repeat(25360, 1))\n",
    "    \n",
    "    x1 = train_feats\n",
    "    x2 = feat.unsqueeze(0).repeat(25360 ,1)\n",
    "    d1 = learn.model.calculate_distance(x1 , x2)\n",
    "    d2 = (x1 + x2)\n",
    "    d3 = (x1*x2)\n",
    "    d4 = (x1-x2)*(x1 - x2)\n",
    "    concat_layer = torch.cat([d1 ,d2,d3, d4]  ,dim = 1)\n",
    "    concat_layer = concat_layer.view( - 1, 1, num_features_model(learn.model.cnn) , 4)   ## no of channels is second dimension\n",
    "    concat_layer  = F.relu(learn.model.conv1(concat_layer.cuda()))\n",
    "    concat_layer = concat_layer.view(-1 ,1,32, num_features_model(learn.model.cnn)  )\n",
    "    concat_layer = F.relu(learn.model.conv2(concat_layer))\n",
    "    concat_layer_fn = concat_layer.view(-1 ,num_features_model(learn.model.cnn) )\n",
    "    predicted_similarity = learn.model.head(concat_layer_fn).sigmoid_()  #.cuda()\n",
    "    sims.append(predicted_similarity.squeeze().detach().cpu())\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.8 s, sys: 292 ms, total: 27.1 s\n",
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "thresh = 1#0.95\n",
    "\n",
    "top_5s = []\n",
    "\n",
    "for sim in sims:\n",
    "    idxs = sim.argsort(descending = True)\n",
    "    probs = sim[idxs]\n",
    "    top_5 = []\n",
    "    \n",
    "    \n",
    "    for  i , p in zip(idxs , probs):\n",
    "        if new_whale_idx not in top_5 and p < thresh  and len(top_5) < 5:\n",
    "            top_5.append(new_whale_idx)\n",
    "        if len(top_5) ==5: break\n",
    "        #if i == new_whale_idx: continue\n",
    "        predicted_class = train_class_idxs[i]\n",
    "        #print(predicted_class)\n",
    "        if predicted_class == new_whale_idx: continue\n",
    "        if predicted_class not in top_5:\n",
    "            top_5.append(predicted_class)\n",
    "    top_5s.append(top_5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_classes  = []\n",
    "\n",
    "for top_5 in top_5s:\n",
    "    top_5_classes.append(' '.join([classes[t] for t in top_5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w_27597ff new_whale w_0e4b65e w_2c0f96c w_73b2fe3',\n",
       " 'new_whale w_114a297 w_6cda039 w_c1efffb w_5010896',\n",
       " 'new_whale w_3982e1e w_51e7506 w_d9d1e17 w_cd4cb49',\n",
       " 'new_whale w_d066c0a w_72288ee w_c8bbb43 w_ac2c28e',\n",
       " 'new_whale w_ae393cd w_bb2c919 w_da011a1 w_61b9586']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'Image': [path.name for path in data.test_ds.x.items]})\n",
    "sub['Id'] = top_5_classes\n",
    "name2 = 'martin_siamene_network_15k_training_images'\n",
    "sub.to_csv(f'data/whale/subs/{name2}.csv', index=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7523869346733668"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'data/whale/subs/{name2}.csv').Id.str.split().apply(lambda x: x[0] == 'new_whale').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/FRACTAL/jitesh.arora/.kaggle/kaggle.json'\n",
      "100%|| 498k/498k [00:06<00:00, 74.4kB/s]\n",
      "Successfully submitted to Humpback Whale Identification"
     ]
    }
   ],
   "source": [
    "#name = 'Ensembleing_resnet50_renet101_siamene_v1'\n",
    "! kaggle competitions submit -c humpback-whale-identification -f data/whale/subs/{name}.csv -m \"resnet18 arch prob 1 for new whales\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
